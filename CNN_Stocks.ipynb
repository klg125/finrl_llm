{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7skcF57_ZMyI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Assuming we have the task2_stocks.csv file already available in the environment\n",
        "file_path = 'task2_stocks.csv'  # Update with actual path if needed\n",
        "\n",
        "# Load the CSV data\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Filter for AAPL stock only\n",
        "df_aapl = df[df['Ticker'] == 'AAPL'].copy()\n",
        "\n",
        "# Sort data by date for accurate calculation of indicators\n",
        "df_aapl['Date'] = pd.to_datetime(df_aapl['Date'])\n",
        "df_aapl = df_aapl.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "# Define RSI calculation\n",
        "def calculate_rsi(df, column='Adj Close', period=14):\n",
        "    delta = df[column].diff()\n",
        "    gain = np.where(delta > 0, delta, 0)\n",
        "    loss = np.where(delta < 0, -delta, 0)\n",
        "\n",
        "    avg_gain = pd.Series(gain).rolling(window=period).mean()\n",
        "    avg_loss = pd.Series(loss).rolling(window=period).mean()\n",
        "\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "\n",
        "    return rsi\n",
        "\n",
        "# Define MACD calculation\n",
        "def calculate_macd(df, column='Adj Close', short_period=12, long_period=26, signal_period=9):\n",
        "    short_ema = df[column].ewm(span=short_period, adjust=False).mean()\n",
        "    long_ema = df[column].ewm(span=long_period, adjust=False).mean()\n",
        "    macd = short_ema - long_ema\n",
        "    macd_signal = macd.ewm(span=signal_period, adjust=False).mean()\n",
        "    macd_hist = macd - macd_signal\n",
        "\n",
        "    return macd, macd_signal, macd_hist\n",
        "\n",
        "# Define Momentum calculation\n",
        "def calculate_momentum(df, column='Adj Close', period=10):\n",
        "    momentum = df[column].diff(period)\n",
        "    return momentum\n",
        "\n",
        "# Define Ultimate Oscillator calculation\n",
        "def calculate_ultimate_oscillator(df, period1=7, period2=14, period3=28):\n",
        "    high_low = df['High'] - df['Low']\n",
        "    high_close_prev = abs(df['High'] - df['Close'].shift(1))\n",
        "    low_close_prev = abs(df['Low'] - df['Close'].shift(1))\n",
        "\n",
        "    true_range = high_low.combine(high_close_prev, max).combine(low_close_prev, max)\n",
        "\n",
        "    bp = df['Close'] - np.minimum(df['Low'], df['Close'].shift(1))\n",
        "    avg7 = bp.rolling(window=period1).sum() / true_range.rolling(window=period1).sum()\n",
        "    avg14 = bp.rolling(window=period2).sum() / true_range.rolling(window=period2).sum()\n",
        "    avg28 = bp.rolling(window=period3).sum() / true_range.rolling(window=period3).sum()\n",
        "\n",
        "    ultimate_oscillator = 100 * ((4 * avg7) + (2 * avg14) + avg28) / (4 + 2 + 1)\n",
        "\n",
        "    return ultimate_oscillator\n",
        "\n",
        "# Apply indicators to AAPL DataFrame\n",
        "df_aapl['RSI'] = calculate_rsi(df_aapl)\n",
        "df_aapl['MACD'], df_aapl['MACD_Signal'], df_aapl['MACD_Hist'] = calculate_macd(df_aapl)\n",
        "df_aapl['Momentum'] = calculate_momentum(df_aapl)\n",
        "df_aapl['Ultimate Oscillator'] = calculate_ultimate_oscillator(df_aapl)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "RuVmgUk2bTmH",
        "outputId": "f5dede0b-88fc-4602-ca8c-3d63a1e2c21e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_aapl_filtered\",\n  \"rows\": 969,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2020-02-12 00:00:00\",\n        \"max\": \"2023-12-15 00:00:00\",\n        \"num_unique_values\": 969,\n        \"samples\": [\n          \"2022-05-24 00:00:00\",\n          \"2021-02-23 00:00:00\",\n          \"2021-08-26 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31.801511812524517,\n        \"min\": 56.09249877929688,\n        \"max\": 198.1100006103516,\n        \"num_unique_values\": 920,\n        \"samples\": [\n          127.0999984741211,\n          149.7100067138672,\n          166.4199981689453\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.04912333211635,\n        \"min\": 54.569732666015625,\n        \"max\": 197.36106872558597,\n        \"num_unique_values\": 957,\n        \"samples\": [\n          185.4791259765625,\n          169.58155822753906,\n          140.67010498046875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54574197,\n        \"min\": 24048300,\n        \"max\": 426510000,\n        \"num_unique_values\": 967,\n        \"samples\": [\n          106239800,\n          195432700,\n          54274900\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AAPL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RSI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.818986178663597,\n        \"min\": 3.17976412294837,\n        \"max\": 93.2419768255155,\n        \"num_unique_values\": 969,\n        \"samples\": [\n          28.754636417804363\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MACD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.6917842964459906,\n        \"min\": -6.525468028942214,\n        \"max\": 7.373554483332768,\n        \"num_unique_values\": 969,\n        \"samples\": [\n          -6.2824498222904595\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MACD_Signal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.5093169089644225,\n        \"min\": -5.685070448607619,\n        \"max\": 6.776131814888314,\n        \"num_unique_values\": 969,\n        \"samples\": [\n          -5.535470056013836\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MACD_Hist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8563329167348377,\n        \"min\": -2.459733980828428,\n        \"max\": 2.3416956199206087,\n        \"num_unique_values\": 969,\n        \"samples\": [\n          -0.7469797662766231\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Momentum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.8635254528731,\n        \"min\": -24.64874267578125,\n        \"max\": 24.63580322265625,\n        \"num_unique_values\": 968,\n        \"samples\": [\n          -13.975494384765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ultimate Oscillator\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.93036649799151,\n        \"min\": 23.835243245163987,\n        \"max\": 78.7349270745208,\n        \"num_unique_values\": 969,\n        \"samples\": [\n          45.68417918187644\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"buy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_aapl_filtered"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c6e78fa1-6738-4349-8001-885a8f4e5908\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>RSI</th>\n",
              "      <th>MACD</th>\n",
              "      <th>MACD_Signal</th>\n",
              "      <th>MACD_Hist</th>\n",
              "      <th>Momentum</th>\n",
              "      <th>Ultimate Oscillator</th>\n",
              "      <th>buy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2020-02-12</td>\n",
              "      <td>81.800003</td>\n",
              "      <td>79.579346</td>\n",
              "      <td>113730400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>55.958395</td>\n",
              "      <td>1.033660</td>\n",
              "      <td>0.954355</td>\n",
              "      <td>0.079304</td>\n",
              "      <td>0.882362</td>\n",
              "      <td>66.317622</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2020-02-13</td>\n",
              "      <td>81.217499</td>\n",
              "      <td>79.012642</td>\n",
              "      <td>94747600</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>54.899557</td>\n",
              "      <td>1.059350</td>\n",
              "      <td>0.975354</td>\n",
              "      <td>0.083996</td>\n",
              "      <td>0.429703</td>\n",
              "      <td>62.107362</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2020-02-14</td>\n",
              "      <td>81.237503</td>\n",
              "      <td>79.032112</td>\n",
              "      <td>80113600</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>62.796070</td>\n",
              "      <td>1.068958</td>\n",
              "      <td>0.994075</td>\n",
              "      <td>0.074883</td>\n",
              "      <td>3.933449</td>\n",
              "      <td>64.843759</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2020-02-18</td>\n",
              "      <td>79.750000</td>\n",
              "      <td>77.585007</td>\n",
              "      <td>152531200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>51.646919</td>\n",
              "      <td>0.948866</td>\n",
              "      <td>0.985033</td>\n",
              "      <td>-0.036168</td>\n",
              "      <td>2.692589</td>\n",
              "      <td>58.196355</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2020-02-19</td>\n",
              "      <td>80.904999</td>\n",
              "      <td>78.708641</td>\n",
              "      <td>93984000</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>50.039552</td>\n",
              "      <td>0.933597</td>\n",
              "      <td>0.974746</td>\n",
              "      <td>-0.041149</td>\n",
              "      <td>1.343727</td>\n",
              "      <td>63.006012</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>2023-12-11</td>\n",
              "      <td>193.179993</td>\n",
              "      <td>192.449707</td>\n",
              "      <td>60943700</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>54.474897</td>\n",
              "      <td>3.444939</td>\n",
              "      <td>3.484142</td>\n",
              "      <td>-0.039203</td>\n",
              "      <td>3.377167</td>\n",
              "      <td>59.080977</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>2023-12-12</td>\n",
              "      <td>194.710007</td>\n",
              "      <td>193.973953</td>\n",
              "      <td>52696900</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>60.149668</td>\n",
              "      <td>3.422158</td>\n",
              "      <td>3.471745</td>\n",
              "      <td>-0.049588</td>\n",
              "      <td>4.293732</td>\n",
              "      <td>61.489651</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>2023-12-13</td>\n",
              "      <td>197.960007</td>\n",
              "      <td>197.211655</td>\n",
              "      <td>70404200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>64.692911</td>\n",
              "      <td>3.623588</td>\n",
              "      <td>3.502114</td>\n",
              "      <td>0.121474</td>\n",
              "      <td>8.557526</td>\n",
              "      <td>66.821153</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>2023-12-14</td>\n",
              "      <td>198.110001</td>\n",
              "      <td>197.361069</td>\n",
              "      <td>66831600</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>68.983202</td>\n",
              "      <td>3.752028</td>\n",
              "      <td>3.552097</td>\n",
              "      <td>0.199931</td>\n",
              "      <td>8.129135</td>\n",
              "      <td>64.310054</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>2023-12-15</td>\n",
              "      <td>197.570007</td>\n",
              "      <td>196.823120</td>\n",
              "      <td>128256700</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>67.844064</td>\n",
              "      <td>3.766986</td>\n",
              "      <td>3.595074</td>\n",
              "      <td>0.171912</td>\n",
              "      <td>6.306061</td>\n",
              "      <td>67.289011</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>969 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6e78fa1-6738-4349-8001-885a8f4e5908')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6e78fa1-6738-4349-8001-885a8f4e5908 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6e78fa1-6738-4349-8001-885a8f4e5908');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ae41cebf-49da-4c74-ac9e-0c55138ec735\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae41cebf-49da-4c74-ac9e-0c55138ec735')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ae41cebf-49da-4c74-ac9e-0c55138ec735 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_186c0ca5-220f-4a0f-bffa-98da1273a902\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_aapl_filtered')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_186c0ca5-220f-4a0f-bffa-98da1273a902 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_aapl_filtered');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          Date       Close   Adj Close     Volume Ticker        RSI      MACD  \\\n",
              "28  2020-02-12   81.800003   79.579346  113730400   AAPL  55.958395  1.033660   \n",
              "29  2020-02-13   81.217499   79.012642   94747600   AAPL  54.899557  1.059350   \n",
              "30  2020-02-14   81.237503   79.032112   80113600   AAPL  62.796070  1.068958   \n",
              "31  2020-02-18   79.750000   77.585007  152531200   AAPL  51.646919  0.948866   \n",
              "32  2020-02-19   80.904999   78.708641   93984000   AAPL  50.039552  0.933597   \n",
              "..         ...         ...         ...        ...    ...        ...       ...   \n",
              "992 2023-12-11  193.179993  192.449707   60943700   AAPL  54.474897  3.444939   \n",
              "993 2023-12-12  194.710007  193.973953   52696900   AAPL  60.149668  3.422158   \n",
              "994 2023-12-13  197.960007  197.211655   70404200   AAPL  64.692911  3.623588   \n",
              "995 2023-12-14  198.110001  197.361069   66831600   AAPL  68.983202  3.752028   \n",
              "996 2023-12-15  197.570007  196.823120  128256700   AAPL  67.844064  3.766986   \n",
              "\n",
              "     MACD_Signal  MACD_Hist  Momentum  Ultimate Oscillator  buy  \n",
              "28      0.954355   0.079304  0.882362            66.317622    0  \n",
              "29      0.975354   0.083996  0.429703            62.107362    0  \n",
              "30      0.994075   0.074883  3.933449            64.843759    0  \n",
              "31      0.985033  -0.036168  2.692589            58.196355    0  \n",
              "32      0.974746  -0.041149  1.343727            63.006012    0  \n",
              "..           ...        ...       ...                  ...  ...  \n",
              "992     3.484142  -0.039203  3.377167            59.080977    0  \n",
              "993     3.471745  -0.049588  4.293732            61.489651    0  \n",
              "994     3.502114   0.121474  8.557526            66.821153    0  \n",
              "995     3.552097   0.199931  8.129135            64.310054    0  \n",
              "996     3.595074   0.171912  6.306061            67.289011    0  \n",
              "\n",
              "[969 rows x 12 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filtering out rows with NaN values and dropping 'Open', 'High', and 'Low' columns\n",
        "df_aapl_filtered = df_aapl.dropna().drop(columns=['Open', 'High', 'Low'])\n",
        "\n",
        "# Creating the 'buy' column\n",
        "# If the adjusted close price in 5 days is higher than today's adjusted close, set 'buy' to 1, else 0\n",
        "df_aapl_filtered['buy'] = (df_aapl_filtered['Adj Close'].shift(-5) > df_aapl_filtered['Adj Close']).astype(int)\n",
        "df_aapl_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWJJej86e-cE",
        "outputId": "035f1982-d489-4f4f-9d77-161016fa5289"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training with training set up to index 849 and evaluating on index 850\n",
            "Epoch 1/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5641 - loss: 0.6813\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5986 - loss: 0.6633\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6619 - loss: 0.6296\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6716 - loss: 0.6198\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6703 - loss: 0.6126\n",
            "Day 850: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 850 and evaluating on index 851\n",
            "Epoch 1/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6149 - loss: 0.6573\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6203 - loss: 0.6476\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6693 - loss: 0.6227\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6743 - loss: 0.6102\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6897 - loss: 0.5954\n",
            "Day 851: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 851 and evaluating on index 852\n",
            "Epoch 1/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5753 - loss: 0.6822\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6275 - loss: 0.6626\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6377 - loss: 0.6328\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6714 - loss: 0.6007\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7035 - loss: 0.5980\n",
            "Day 852: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 852 and evaluating on index 853\n",
            "Epoch 1/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5422 - loss: 0.6896\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6223 - loss: 0.6611\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6569 - loss: 0.6373\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6731 - loss: 0.6193\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6981 - loss: 0.6026\n",
            "Day 853: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 853 and evaluating on index 854\n",
            "Epoch 1/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5573 - loss: 0.6804\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6331 - loss: 0.6454\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6233 - loss: 0.6410\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6823 - loss: 0.6137\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6947 - loss: 0.5808\n",
            "Day 854: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 854 and evaluating on index 855\n",
            "Epoch 1/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5234 - loss: 0.6953\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6819 - loss: 0.6443\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6357 - loss: 0.6336\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6539 - loss: 0.6162\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7321 - loss: 0.5823\n",
            "Day 855: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 855 and evaluating on index 856\n",
            "Epoch 1/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5669 - loss: 0.6874\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5947 - loss: 0.6611\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6387 - loss: 0.6387\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6775 - loss: 0.6141\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6589 - loss: 0.6100\n",
            "Day 856: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 856 and evaluating on index 857\n",
            "Epoch 1/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5833 - loss: 0.6753\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6345 - loss: 0.6444\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6567 - loss: 0.6209\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7119 - loss: 0.5997\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6991 - loss: 0.6008\n",
            "Day 857: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 857 and evaluating on index 858\n",
            "Epoch 1/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4918 - loss: 0.7043\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5996 - loss: 0.6598\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6415 - loss: 0.6313\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6609 - loss: 0.6272\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6554 - loss: 0.6274\n",
            "Day 858: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 858 and evaluating on index 859\n",
            "Epoch 1/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5822 - loss: 0.6756\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6010 - loss: 0.6548\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6123 - loss: 0.6440\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6812 - loss: 0.5980\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6840 - loss: 0.6043\n",
            "Day 859: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 859 and evaluating on index 860\n",
            "Epoch 1/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5807 - loss: 0.6738\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6306 - loss: 0.6446\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6863 - loss: 0.6179\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6835 - loss: 0.6158\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7067 - loss: 0.6039\n",
            "Day 860: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 860 and evaluating on index 861\n",
            "Epoch 1/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5759 - loss: 0.6774\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5876 - loss: 0.6536\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6516 - loss: 0.6188\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6739 - loss: 0.6207\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7263 - loss: 0.5865\n",
            "Day 861: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 861 and evaluating on index 862\n",
            "Epoch 1/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5466 - loss: 0.6915\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6622 - loss: 0.6429\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6588 - loss: 0.6363\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6801 - loss: 0.6111\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6884 - loss: 0.6121\n",
            "Day 862: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 862 and evaluating on index 863\n",
            "Epoch 1/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5462 - loss: 0.6858\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5893 - loss: 0.6676\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6064 - loss: 0.6465\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6685 - loss: 0.6155\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6967 - loss: 0.6084\n",
            "Day 863: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 863 and evaluating on index 864\n",
            "Epoch 1/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5658 - loss: 0.6747\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6344 - loss: 0.6405\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6533 - loss: 0.6280\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6518 - loss: 0.6236\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7144 - loss: 0.5940\n",
            "Day 864: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 864 and evaluating on index 865\n",
            "Epoch 1/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5786 - loss: 0.6779\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6048 - loss: 0.6547\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6572 - loss: 0.6282\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6950 - loss: 0.6080\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7020 - loss: 0.5975\n",
            "Day 865: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 865 and evaluating on index 866\n",
            "Epoch 1/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5026 - loss: 0.6983\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6397 - loss: 0.6407\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6688 - loss: 0.6407\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6419 - loss: 0.6278\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6905 - loss: 0.6171\n",
            "Day 866: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 866 and evaluating on index 867\n",
            "Epoch 1/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5649 - loss: 0.6822\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5897 - loss: 0.6628\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6430 - loss: 0.6300\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6606 - loss: 0.6257\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6698 - loss: 0.6147\n",
            "Day 867: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 867 and evaluating on index 868\n",
            "Epoch 1/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5225 - loss: 0.6887\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6314 - loss: 0.6476\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6587 - loss: 0.6404\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6586 - loss: 0.6229\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6922 - loss: 0.6041\n",
            "Day 868: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 868 and evaluating on index 869\n",
            "Epoch 1/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5623 - loss: 0.6862\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6450 - loss: 0.6392\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6789 - loss: 0.6303\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6769 - loss: 0.6104\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7108 - loss: 0.6121\n",
            "Day 869: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 869 and evaluating on index 870\n",
            "Epoch 1/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5668 - loss: 0.6854\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6355 - loss: 0.6490\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6209 - loss: 0.6410\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6787 - loss: 0.6008\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7044 - loss: 0.6041\n",
            "Day 870: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 870 and evaluating on index 871\n",
            "Epoch 1/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5638 - loss: 0.6805\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6180 - loss: 0.6531\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6463 - loss: 0.6319\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6640 - loss: 0.5978\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6741 - loss: 0.6095\n",
            "Day 871: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 871 and evaluating on index 872\n",
            "Epoch 1/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5636 - loss: 0.6792\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6290 - loss: 0.6438\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6522 - loss: 0.6263\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6564 - loss: 0.6330\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6822 - loss: 0.6015\n",
            "Day 872: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 872 and evaluating on index 873\n",
            "Epoch 1/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5379 - loss: 0.6921\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5899 - loss: 0.6602\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6712 - loss: 0.6237\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6490 - loss: 0.6189\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7047 - loss: 0.5817\n",
            "Day 873: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 873 and evaluating on index 874\n",
            "Epoch 1/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5608 - loss: 0.6898\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6258 - loss: 0.6459\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6465 - loss: 0.6303\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6789 - loss: 0.6102\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6809 - loss: 0.5995\n",
            "Day 874: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 874 and evaluating on index 875\n",
            "Epoch 1/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5608 - loss: 0.6814\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6422 - loss: 0.6370\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6660 - loss: 0.6223\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6644 - loss: 0.6187\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7160 - loss: 0.5939\n",
            "Day 875: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 875 and evaluating on index 876\n",
            "Epoch 1/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5258 - loss: 0.6895\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6147 - loss: 0.6472\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6579 - loss: 0.6291\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6881 - loss: 0.5942\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7189 - loss: 0.5882\n",
            "Day 876: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 876 and evaluating on index 877\n",
            "Epoch 1/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5809 - loss: 0.6862\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6035 - loss: 0.6525\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6381 - loss: 0.6372\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6484 - loss: 0.6215\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6739 - loss: 0.6046\n",
            "Day 877: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 877 and evaluating on index 878\n",
            "Epoch 1/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5973 - loss: 0.6776\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6416 - loss: 0.6414\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6584 - loss: 0.6349\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6941 - loss: 0.6105\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6732 - loss: 0.5999\n",
            "Day 878: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 878 and evaluating on index 879\n",
            "Epoch 1/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5187 - loss: 0.6895\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6156 - loss: 0.6598\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6386 - loss: 0.6439\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6455 - loss: 0.6382\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6757 - loss: 0.6103\n",
            "Day 879: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 879 and evaluating on index 880\n",
            "Epoch 1/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6014 - loss: 0.6706\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6071 - loss: 0.6536\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6436 - loss: 0.6446\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6784 - loss: 0.6079\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6971 - loss: 0.6081\n",
            "Day 880: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 880 and evaluating on index 881\n",
            "Epoch 1/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5587 - loss: 0.6824\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5923 - loss: 0.6607\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6344 - loss: 0.6415\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6751 - loss: 0.6099\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6758 - loss: 0.6106\n",
            "Day 881: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 881 and evaluating on index 882\n",
            "Epoch 1/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5185 - loss: 0.6921\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5770 - loss: 0.6774\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6208 - loss: 0.6427\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6779 - loss: 0.6277\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6676 - loss: 0.6062\n",
            "Day 882: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 882 and evaluating on index 883\n",
            "Epoch 1/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5739 - loss: 0.6793\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6446 - loss: 0.6498\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6856 - loss: 0.6317\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6875 - loss: 0.6133\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6851 - loss: 0.5986\n",
            "Day 883: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 883 and evaluating on index 884\n",
            "Epoch 1/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5529 - loss: 0.6889\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5728 - loss: 0.6682\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6553 - loss: 0.6328\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6609 - loss: 0.6277\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6839 - loss: 0.6106\n",
            "Day 884: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 884 and evaluating on index 885\n",
            "Epoch 1/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5875 - loss: 0.6789\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6381 - loss: 0.6407\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6459 - loss: 0.6261\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6681 - loss: 0.6317\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6803 - loss: 0.6082\n",
            "Day 885: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 885 and evaluating on index 886\n",
            "Epoch 1/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5760 - loss: 0.6842\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5910 - loss: 0.6662\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6113 - loss: 0.6527\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6469 - loss: 0.6282\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6750 - loss: 0.6224\n",
            "Day 886: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 886 and evaluating on index 887\n",
            "Epoch 1/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5740 - loss: 0.6781\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6239 - loss: 0.6469\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6672 - loss: 0.6326\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6515 - loss: 0.6346\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6957 - loss: 0.6004\n",
            "Day 887: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 887 and evaluating on index 888\n",
            "Epoch 1/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5421 - loss: 0.6847\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6111 - loss: 0.6388\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6705 - loss: 0.6199\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6851 - loss: 0.6175\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6606 - loss: 0.6224\n",
            "Day 888: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 888 and evaluating on index 889\n",
            "Epoch 1/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5702 - loss: 0.6869\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6228 - loss: 0.6567\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6375 - loss: 0.6385\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6494 - loss: 0.6191\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6875 - loss: 0.5957\n",
            "Day 889: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 889 and evaluating on index 890\n",
            "Epoch 1/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5218 - loss: 0.6937\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6441 - loss: 0.6370\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6207 - loss: 0.6465\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6802 - loss: 0.6227\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6886 - loss: 0.6063\n",
            "Day 890: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 890 and evaluating on index 891\n",
            "Epoch 1/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5604 - loss: 0.6740\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6203 - loss: 0.6589\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6285 - loss: 0.6376\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6796 - loss: 0.6152\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6786 - loss: 0.6028\n",
            "Day 891: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 891 and evaluating on index 892\n",
            "Epoch 1/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5325 - loss: 0.6848\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6134 - loss: 0.6502\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6133 - loss: 0.6464\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6640 - loss: 0.6247\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6410 - loss: 0.6364\n",
            "Day 892: Test Accuracy = 0.0\n",
            "\n",
            "Training with training set up to index 892 and evaluating on index 893\n",
            "Epoch 1/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5624 - loss: 0.6744\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5985 - loss: 0.6503\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6485 - loss: 0.6268\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6779 - loss: 0.6050\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6583 - loss: 0.6142\n",
            "Day 893: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 893 and evaluating on index 894\n",
            "Epoch 1/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5685 - loss: 0.6851\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6050 - loss: 0.6522\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6258 - loss: 0.6406\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6254 - loss: 0.6442\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6907 - loss: 0.6032\n",
            "Day 894: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 894 and evaluating on index 895\n",
            "Epoch 1/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5206 - loss: 0.6883\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6159 - loss: 0.6464\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6217 - loss: 0.6543\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6550 - loss: 0.6205\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6987 - loss: 0.6055\n",
            "Day 895: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 895 and evaluating on index 896\n",
            "Epoch 1/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5606 - loss: 0.6832\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6100 - loss: 0.6633\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6583 - loss: 0.6323\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6720 - loss: 0.6326\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6904 - loss: 0.6041\n",
            "Day 896: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 896 and evaluating on index 897\n",
            "Epoch 1/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5508 - loss: 0.6844\n",
            "Epoch 2/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6392 - loss: 0.6534\n",
            "Epoch 3/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6158 - loss: 0.6378\n",
            "Epoch 4/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6521 - loss: 0.6227\n",
            "Epoch 5/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6395 - loss: 0.6285\n",
            "Day 897: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 897 and evaluating on index 898\n",
            "Epoch 1/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5134 - loss: 0.6890\n",
            "Epoch 2/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5969 - loss: 0.6434\n",
            "Epoch 3/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6432 - loss: 0.6298\n",
            "Epoch 4/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6635 - loss: 0.5986\n",
            "Epoch 5/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6849 - loss: 0.5880\n",
            "Day 898: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 898 and evaluating on index 899\n",
            "Epoch 1/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5157 - loss: 0.6876\n",
            "Epoch 2/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6445 - loss: 0.6379\n",
            "Epoch 3/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6265 - loss: 0.6348\n",
            "Epoch 4/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6552 - loss: 0.6225\n",
            "Epoch 5/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6750 - loss: 0.6030\n",
            "Day 899: Test Accuracy = 1.0\n",
            "\n",
            "Training with training set up to index 899 and evaluating on index 900\n",
            "Epoch 1/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5272 - loss: 0.6863\n",
            "Epoch 2/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6275 - loss: 0.6467\n",
            "Epoch 3/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6158 - loss: 0.6480\n",
            "Epoch 4/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6718 - loss: 0.5896\n",
            "Epoch 5/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6671 - loss: 0.6119\n",
            "Day 900: Test Accuracy = 1.0\n",
            "\n",
            "Average Test Accuracy from Day 801 to 900: 0.5294117647058824\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Remove the last 5 rows and reset index\n",
        "df_aapl_filtered = df_aapl_filtered.iloc[:-5].reset_index(drop=True)\n",
        "\n",
        "# Define features and target\n",
        "features = ['Close', 'RSI', 'MACD', 'MACD_Signal', 'MACD_Hist', 'Momentum', 'Ultimate Oscillator']\n",
        "X = df_aapl_filtered[features]\n",
        "y = df_aapl_filtered['buy']\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Set up the time series sequences\n",
        "sequence_length = 10  # Use past 10 days\n",
        "X_seq, y_seq = [], []\n",
        "\n",
        "for i in range(len(X_scaled) - sequence_length):\n",
        "    X_seq.append(X_scaled[i:i + sequence_length])  # past 10 days data as features\n",
        "    y_seq.append(y.iloc[i + sequence_length])      # target is the 'buy' value on the 11th day\n",
        "\n",
        "X_seq, y_seq = np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# Define test start and end indices for the expanding window\n",
        "test_start = 850\n",
        "test_end = 900\n",
        "\n",
        "# Store results\n",
        "test_acc_list = []\n",
        "\n",
        "# Loop for each test point from 801 to 900\n",
        "for i in range(test_start, test_end + 1):\n",
        "    # Define expanding training set up to the current index\n",
        "    X_train = X_seq[:i]\n",
        "    y_train = y_seq[:i]\n",
        "    X_test = X_seq[i:i + 1]  # Single day\n",
        "    y_test = y_seq[i:i + 1]\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(sequence_length, X_train.shape[2])),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "        tf.keras.layers.Conv1D(filters=32, kernel_size=2, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(50, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model for 30 epochs\n",
        "    print(f\"\\nTraining with training set up to index {i - 1} and evaluating on index {i}\")\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=16, verbose=1)\n",
        "\n",
        "    # Evaluate the model on the single test day\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    test_acc_list.append(test_acc)\n",
        "    print(f\"Day {i}: Test Accuracy = {test_acc}\")\n",
        "\n",
        "# Calculate and print the average test accuracy across all days\n",
        "average_test_acc = np.mean(test_acc_list)\n",
        "print(\"\\nAverage Test Accuracy from Day 801 to 900:\", average_test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RNBCv4dc_yUt",
        "outputId": "042151aa-c3d5-4e74-96f2-9c0fd88b15c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5929 - loss: 0.6740\n",
            "Epoch 2/5\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6118 - loss: 0.6505\n",
            "Epoch 3/5\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6284 - loss: 0.6338\n",
            "Epoch 4/5\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6507 - loss: 0.6249\n",
            "Epoch 5/5\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6802 - loss: 0.6025\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5818 - loss: 0.6707\n",
            "Epoch 2/5\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6404 - loss: 0.6427\n",
            "Epoch 3/5\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6239 - loss: 0.6338\n",
            "Epoch 4/5\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6810 - loss: 0.6186\n",
            "Epoch 5/5\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6610 - loss: 0.5999\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5352 - loss: 0.6868\n",
            "Epoch 2/5\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6199 - loss: 0.6329\n",
            "Epoch 3/5\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6489 - loss: 0.6258\n",
            "Epoch 4/5\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6776 - loss: 0.6218\n",
            "Epoch 5/5\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6718 - loss: 0.6097\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5283 - loss: 0.6875\n",
            "Epoch 2/5\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6065 - loss: 0.6461\n",
            "Epoch 3/5\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6200 - loss: 0.6511\n",
            "Epoch 4/5\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6520 - loss: 0.6110\n",
            "Epoch 5/5\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7292 - loss: 0.5700\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5532 - loss: 0.6765\n",
            "Epoch 2/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5965 - loss: 0.6560\n",
            "Epoch 3/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6514 - loss: 0.6350\n",
            "Epoch 4/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6539 - loss: 0.6181\n",
            "Epoch 5/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7119 - loss: 0.6042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c18cbd0dab0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5809 - loss: 0.6789\n",
            "Epoch 2/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6152 - loss: 0.6535\n",
            "Epoch 3/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6324 - loss: 0.6490\n",
            "Epoch 4/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6561 - loss: 0.6288\n",
            "Epoch 5/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6639 - loss: 0.6287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c18c96c4670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5159 - loss: 0.6894\n",
            "Epoch 2/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6395 - loss: 0.6418\n",
            "Epoch 3/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6080 - loss: 0.6470\n",
            "Epoch 4/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6507 - loss: 0.6253\n",
            "Epoch 5/5\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6809 - loss: 0.6091\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5095 - loss: 0.6899\n",
            "Epoch 2/5\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6300 - loss: 0.6447\n",
            "Epoch 3/5\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6615 - loss: 0.6308\n",
            "Epoch 4/5\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6758 - loss: 0.6203\n",
            "Epoch 5/5\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7019 - loss: 0.5991\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5369 - loss: 0.6861\n",
            "Epoch 2/5\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5727 - loss: 0.6608\n",
            "Epoch 3/5\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6392 - loss: 0.6252\n",
            "Epoch 4/5\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6627 - loss: 0.6145\n",
            "Epoch 5/5\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6620 - loss: 0.6108\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5932 - loss: 0.6662\n",
            "Epoch 2/5\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6107 - loss: 0.6617\n",
            "Epoch 3/5\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6821 - loss: 0.6327\n",
            "Epoch 4/5\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6771 - loss: 0.6161\n",
            "Epoch 5/5\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6981 - loss: 0.6090\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5993 - loss: 0.6737\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6234 - loss: 0.6447\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6290 - loss: 0.6397\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6913 - loss: 0.6083\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7047 - loss: 0.5896\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5799 - loss: 0.6805\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6393 - loss: 0.6459\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6747 - loss: 0.6209\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6672 - loss: 0.6147\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6841 - loss: 0.6038\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5631 - loss: 0.6864\n",
            "Epoch 2/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6131 - loss: 0.6562\n",
            "Epoch 3/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6233 - loss: 0.6390\n",
            "Epoch 4/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6620 - loss: 0.6202\n",
            "Epoch 5/5\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6704 - loss: 0.6178\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5516 - loss: 0.6786\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5962 - loss: 0.6574\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6552 - loss: 0.6269\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6822 - loss: 0.6141\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7042 - loss: 0.5890\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5557 - loss: 0.6842\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5905 - loss: 0.6531\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6725 - loss: 0.6302\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6740 - loss: 0.6183\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7028 - loss: 0.5873\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5420 - loss: 0.6896\n",
            "Epoch 2/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6277 - loss: 0.6564\n",
            "Epoch 3/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6330 - loss: 0.6297\n",
            "Epoch 4/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6764 - loss: 0.6105\n",
            "Epoch 5/5\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6959 - loss: 0.6008\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5461 - loss: 0.6870\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6129 - loss: 0.6493\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6501 - loss: 0.6210\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6749 - loss: 0.6046\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6656 - loss: 0.6067\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5218 - loss: 0.6823\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6331 - loss: 0.6488\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6156 - loss: 0.6420\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6691 - loss: 0.6241\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6948 - loss: 0.5955\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6085 - loss: 0.6692\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6249 - loss: 0.6471\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6670 - loss: 0.6159\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6804 - loss: 0.6028\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6600 - loss: 0.6276\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5556 - loss: 0.6852\n",
            "Epoch 2/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6152 - loss: 0.6405\n",
            "Epoch 3/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6768 - loss: 0.6376\n",
            "Epoch 4/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6697 - loss: 0.6180\n",
            "Epoch 5/5\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6856 - loss: 0.6018\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5679 - loss: 0.6817\n",
            "Epoch 2/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6157 - loss: 0.6467\n",
            "Epoch 3/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6479 - loss: 0.6150\n",
            "Epoch 4/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6630 - loss: 0.6205\n",
            "Epoch 5/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6938 - loss: 0.5992\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5467 - loss: 0.6793\n",
            "Epoch 2/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6158 - loss: 0.6555\n",
            "Epoch 3/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6269 - loss: 0.6379\n",
            "Epoch 4/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6504 - loss: 0.6164\n",
            "Epoch 5/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6435 - loss: 0.6259\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5642 - loss: 0.6828\n",
            "Epoch 2/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5983 - loss: 0.6538\n",
            "Epoch 3/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6363 - loss: 0.6403\n",
            "Epoch 4/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6548 - loss: 0.6144\n",
            "Epoch 5/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6695 - loss: 0.6014\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5392 - loss: 0.6817\n",
            "Epoch 2/5\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6314 - loss: 0.6468\n",
            "Epoch 3/5\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6842 - loss: 0.6168\n",
            "Epoch 4/5\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6858 - loss: 0.6213\n",
            "Epoch 5/5\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6738 - loss: 0.6059\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5418 - loss: 0.6904\n",
            "Epoch 2/5\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6490 - loss: 0.6485\n",
            "Epoch 3/5\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6436 - loss: 0.6352\n",
            "Epoch 4/5\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6675 - loss: 0.6091\n",
            "Epoch 5/5\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7119 - loss: 0.5799\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "math domain error",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-1771862519ce>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Generate predictions for the next 5 days\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# Store the predictions back into the original DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/progbar.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnumdigits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                 \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"%\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumdigits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"d/%d\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\x1b[1m{bar}\\x1b[0m \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: math domain error"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Remove the last 5 rows and reset index\n",
        "df_aapl_filtered = df_aapl_filtered.iloc[:-5].reset_index(drop=True)\n",
        "\n",
        "# Define features and target\n",
        "features = ['Close', 'RSI', 'MACD', 'MACD_Signal', 'MACD_Hist', 'Momentum', 'Ultimate Oscillator']\n",
        "X = df_aapl_filtered[features]\n",
        "y = df_aapl_filtered['buy']\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Set up the time series sequences\n",
        "sequence_length = 10  # Use past 10 days\n",
        "X_seq, y_seq = [], []\n",
        "\n",
        "for i in range(len(X_scaled) - sequence_length):\n",
        "    X_seq.append(X_scaled[i:i + sequence_length])  # past 10 days data as features\n",
        "    y_seq.append(y.iloc[i + sequence_length])      # target is the 'buy' value on the 11th day\n",
        "\n",
        "X_seq, y_seq = np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# Define test start and end indices for 5-day blocks\n",
        "test_start = 801\n",
        "test_end = 930\n",
        "\n",
        "# Initialize predictions column in the original DataFrame\n",
        "df_aapl_filtered['prediction'] = np.nan\n",
        "\n",
        "# Loop through each 5-day prediction window\n",
        "for i in range(test_start, test_end + 1, 5):\n",
        "    # Define expanding training set up to the current index\n",
        "    X_train = X_seq[:i]\n",
        "    y_train = y_seq[:i]\n",
        "    X_test = X_seq[i:i + 5]  # Next 5 days for prediction\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(sequence_length, X_train.shape[2])),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "        tf.keras.layers.Conv1D(filters=32, kernel_size=2, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(50, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "    ])\n",
        "\n",
        "    # Compile and train the model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=16, verbose=1)\n",
        "\n",
        "    # Generate predictions for the next 5 days\n",
        "    predictions = model.predict(X_test).flatten()\n",
        "\n",
        "    # Store the predictions back into the original DataFrame\n",
        "    df_aapl_filtered.loc[i + sequence_length:i + sequence_length + 4, 'prediction'] = predictions\n",
        "\n",
        "# Display the DataFrame with predictions\n",
        "print(df_aapl_filtered[['Date', 'buy', 'prediction']].tail(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uqtyAL9jmkRT",
        "outputId": "06afa17e-1974-437b-943d-1dd16233f051"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_aapl_filtered\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-08-10 00:00:00\",\n        \"max\": \"2023-10-19 00:00:00\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"2023-08-29 00:00:00\",\n          \"2023-10-05 00:00:00\",\n          \"2023-09-22 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.37450910246862,\n        \"min\": 170.42999267578125,\n        \"max\": 189.6999969482422,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          175.49000549316406,\n          178.99000549316406,\n          179.07000732421875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.352023979823498,\n        \"min\": 169.5623321533203,\n        \"max\": 188.73423767089844,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          183.18263244628903,\n          177.93948364257812,\n          176.24810791015625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14954717,\n        \"min\": 42084200,\n        \"max\": 112488800,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          53003900,\n          48527900,\n          56725400\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AAPL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RSI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.662235516623117,\n        \"min\": 11.303821174107085,\n        \"max\": 71.39366726235627,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          61.42227991337238\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MACD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.256146865628204,\n        \"min\": -3.8187013336389555,\n        \"max\": 0.6020294086776516,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          -1.97478280272\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MACD_Signal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8133282975212179,\n        \"min\": -3.0154450795581984,\n        \"max\": 0.032167358176725,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          -2.7274293520428987\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MACD_Hist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9737191216839255,\n        \"min\": -2.2625937513426386,\n        \"max\": 1.7778380258799722,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.7526465493228987\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Momentum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.572810478353157,\n        \"min\": -17.805099487304688,\n        \"max\": 14.893798828125,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          6.636047363281222\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ultimate Oscillator\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.933876006302228,\n        \"min\": 26.081247644719355,\n        \"max\": 71.04156448185127,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          61.02167523126527\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"buy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prediction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12222869468693556,\n        \"min\": 0.1427113115787506,\n        \"max\": 0.5643759965896606,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.5405653119087219\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d7edca83-06b6-4600-b488-f7b7b35ed602\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>RSI</th>\n",
              "      <th>MACD</th>\n",
              "      <th>MACD_Signal</th>\n",
              "      <th>MACD_Hist</th>\n",
              "      <th>Momentum</th>\n",
              "      <th>Ultimate Oscillator</th>\n",
              "      <th>buy</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>2023-08-10</td>\n",
              "      <td>177.970001</td>\n",
              "      <td>176.825150</td>\n",
              "      <td>54686900</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>24.553693</td>\n",
              "      <td>-2.230426</td>\n",
              "      <td>0.032167</td>\n",
              "      <td>-2.262594</td>\n",
              "      <td>-15.151932</td>\n",
              "      <td>26.081248</td>\n",
              "      <td>0</td>\n",
              "      <td>0.313292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>880</th>\n",
              "      <td>2023-08-11</td>\n",
              "      <td>177.789993</td>\n",
              "      <td>176.884857</td>\n",
              "      <td>51988100</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>22.434627</td>\n",
              "      <td>-2.638519</td>\n",
              "      <td>-0.501970</td>\n",
              "      <td>-2.136549</td>\n",
              "      <td>-17.685425</td>\n",
              "      <td>28.332647</td>\n",
              "      <td>0</td>\n",
              "      <td>0.251857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>881</th>\n",
              "      <td>2023-08-14</td>\n",
              "      <td>179.460007</td>\n",
              "      <td>178.546371</td>\n",
              "      <td>43675600</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>24.697356</td>\n",
              "      <td>-2.795640</td>\n",
              "      <td>-0.960704</td>\n",
              "      <td>-1.834936</td>\n",
              "      <td>-16.639908</td>\n",
              "      <td>32.224822</td>\n",
              "      <td>0</td>\n",
              "      <td>0.163717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>882</th>\n",
              "      <td>2023-08-15</td>\n",
              "      <td>177.449997</td>\n",
              "      <td>176.546585</td>\n",
              "      <td>43622600</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>20.647179</td>\n",
              "      <td>-3.046407</td>\n",
              "      <td>-1.377845</td>\n",
              "      <td>-1.668563</td>\n",
              "      <td>-17.805099</td>\n",
              "      <td>37.441234</td>\n",
              "      <td>0</td>\n",
              "      <td>0.180028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>883</th>\n",
              "      <td>2023-08-16</td>\n",
              "      <td>176.570007</td>\n",
              "      <td>175.671066</td>\n",
              "      <td>46964900</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>20.938797</td>\n",
              "      <td>-3.278003</td>\n",
              "      <td>-1.757876</td>\n",
              "      <td>-1.520127</td>\n",
              "      <td>-15.670120</td>\n",
              "      <td>37.793791</td>\n",
              "      <td>1</td>\n",
              "      <td>0.187729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>2023-08-17</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>173.114151</td>\n",
              "      <td>66062900</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>11.710541</td>\n",
              "      <td>-3.626066</td>\n",
              "      <td>-2.131514</td>\n",
              "      <td>-1.494552</td>\n",
              "      <td>-16.826096</td>\n",
              "      <td>29.768756</td>\n",
              "      <td>1</td>\n",
              "      <td>0.202567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>2023-08-18</td>\n",
              "      <td>174.490005</td>\n",
              "      <td>173.601669</td>\n",
              "      <td>61114200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>11.303821</td>\n",
              "      <td>-3.818553</td>\n",
              "      <td>-2.468922</td>\n",
              "      <td>-1.349631</td>\n",
              "      <td>-7.217651</td>\n",
              "      <td>35.097160</td>\n",
              "      <td>1</td>\n",
              "      <td>0.193149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>2023-08-21</td>\n",
              "      <td>175.839996</td>\n",
              "      <td>174.944794</td>\n",
              "      <td>46311900</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>15.830985</td>\n",
              "      <td>-3.818701</td>\n",
              "      <td>-2.738878</td>\n",
              "      <td>-1.079823</td>\n",
              "      <td>-2.754730</td>\n",
              "      <td>42.351156</td>\n",
              "      <td>1</td>\n",
              "      <td>0.384552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>2023-08-22</td>\n",
              "      <td>177.229996</td>\n",
              "      <td>176.327698</td>\n",
              "      <td>42084200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>21.959189</td>\n",
              "      <td>-3.664983</td>\n",
              "      <td>-2.924099</td>\n",
              "      <td>-0.740884</td>\n",
              "      <td>-2.315704</td>\n",
              "      <td>44.018561</td>\n",
              "      <td>1</td>\n",
              "      <td>0.366074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>2023-08-23</td>\n",
              "      <td>181.119995</td>\n",
              "      <td>180.197922</td>\n",
              "      <td>52722800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>33.340796</td>\n",
              "      <td>-3.194046</td>\n",
              "      <td>-2.978088</td>\n",
              "      <td>-0.215957</td>\n",
              "      <td>3.154144</td>\n",
              "      <td>47.949240</td>\n",
              "      <td>1</td>\n",
              "      <td>0.365870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>2023-08-24</td>\n",
              "      <td>176.380005</td>\n",
              "      <td>175.482056</td>\n",
              "      <td>54945800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>39.254553</td>\n",
              "      <td>-3.164873</td>\n",
              "      <td>-3.015445</td>\n",
              "      <td>-0.149428</td>\n",
              "      <td>-1.343094</td>\n",
              "      <td>44.944673</td>\n",
              "      <td>1</td>\n",
              "      <td>0.378145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>2023-08-25</td>\n",
              "      <td>178.610001</td>\n",
              "      <td>177.700699</td>\n",
              "      <td>51449600</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>50.002455</td>\n",
              "      <td>-2.928964</td>\n",
              "      <td>-2.998149</td>\n",
              "      <td>0.069185</td>\n",
              "      <td>0.815842</td>\n",
              "      <td>51.652539</td>\n",
              "      <td>1</td>\n",
              "      <td>0.372489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>891</th>\n",
              "      <td>2023-08-28</td>\n",
              "      <td>180.190002</td>\n",
              "      <td>179.272644</td>\n",
              "      <td>43820700</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>51.280930</td>\n",
              "      <td>-2.585359</td>\n",
              "      <td>-2.915591</td>\n",
              "      <td>0.330232</td>\n",
              "      <td>0.726273</td>\n",
              "      <td>57.331010</td>\n",
              "      <td>1</td>\n",
              "      <td>0.564376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>892</th>\n",
              "      <td>2023-08-29</td>\n",
              "      <td>184.119995</td>\n",
              "      <td>183.182632</td>\n",
              "      <td>53003900</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>61.422280</td>\n",
              "      <td>-1.974783</td>\n",
              "      <td>-2.727429</td>\n",
              "      <td>0.752647</td>\n",
              "      <td>6.636047</td>\n",
              "      <td>61.021675</td>\n",
              "      <td>0</td>\n",
              "      <td>0.540565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893</th>\n",
              "      <td>2023-08-30</td>\n",
              "      <td>187.649994</td>\n",
              "      <td>186.694656</td>\n",
              "      <td>60813900</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>66.358834</td>\n",
              "      <td>-1.193745</td>\n",
              "      <td>-2.420692</td>\n",
              "      <td>1.226948</td>\n",
              "      <td>11.023590</td>\n",
              "      <td>64.419697</td>\n",
              "      <td>0</td>\n",
              "      <td>0.554845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>894</th>\n",
              "      <td>2023-08-31</td>\n",
              "      <td>187.869995</td>\n",
              "      <td>186.913528</td>\n",
              "      <td>60794500</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>66.535404</td>\n",
              "      <td>-0.550756</td>\n",
              "      <td>-2.046705</td>\n",
              "      <td>1.495949</td>\n",
              "      <td>13.799377</td>\n",
              "      <td>62.147184</td>\n",
              "      <td>0</td>\n",
              "      <td>0.488132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>2023-09-01</td>\n",
              "      <td>189.460007</td>\n",
              "      <td>188.495468</td>\n",
              "      <td>45732600</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>66.447360</td>\n",
              "      <td>0.085480</td>\n",
              "      <td>-1.620268</td>\n",
              "      <td>1.705748</td>\n",
              "      <td>14.893799</td>\n",
              "      <td>60.107666</td>\n",
              "      <td>0</td>\n",
              "      <td>0.455290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>896</th>\n",
              "      <td>2023-09-05</td>\n",
              "      <td>189.699997</td>\n",
              "      <td>188.734238</td>\n",
              "      <td>45280000</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>71.393667</td>\n",
              "      <td>0.602029</td>\n",
              "      <td>-1.175809</td>\n",
              "      <td>1.777838</td>\n",
              "      <td>13.789444</td>\n",
              "      <td>71.041564</td>\n",
              "      <td>0</td>\n",
              "      <td>0.266339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897</th>\n",
              "      <td>2023-09-06</td>\n",
              "      <td>182.910004</td>\n",
              "      <td>181.978806</td>\n",
              "      <td>81755800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>59.177786</td>\n",
              "      <td>0.460978</td>\n",
              "      <td>-0.848451</td>\n",
              "      <td>1.309429</td>\n",
              "      <td>5.651108</td>\n",
              "      <td>57.500625</td>\n",
              "      <td>0</td>\n",
              "      <td>0.243822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>2023-09-07</td>\n",
              "      <td>177.559998</td>\n",
              "      <td>176.656021</td>\n",
              "      <td>112488800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>54.769549</td>\n",
              "      <td>-0.079396</td>\n",
              "      <td>-0.694640</td>\n",
              "      <td>0.615244</td>\n",
              "      <td>-3.541901</td>\n",
              "      <td>53.989427</td>\n",
              "      <td>0</td>\n",
              "      <td>0.215394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>899</th>\n",
              "      <td>2023-09-08</td>\n",
              "      <td>178.179993</td>\n",
              "      <td>177.272858</td>\n",
              "      <td>65551300</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>54.926533</td>\n",
              "      <td>-0.452655</td>\n",
              "      <td>-0.646243</td>\n",
              "      <td>0.193589</td>\n",
              "      <td>1.790802</td>\n",
              "      <td>48.146750</td>\n",
              "      <td>0</td>\n",
              "      <td>0.215388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>900</th>\n",
              "      <td>2023-09-11</td>\n",
              "      <td>179.360001</td>\n",
              "      <td>178.446869</td>\n",
              "      <td>58953100</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>54.721020</td>\n",
              "      <td>-0.646282</td>\n",
              "      <td>-0.646251</td>\n",
              "      <td>-0.000031</td>\n",
              "      <td>0.746170</td>\n",
              "      <td>45.820708</td>\n",
              "      <td>0</td>\n",
              "      <td>0.209773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>901</th>\n",
              "      <td>2023-09-12</td>\n",
              "      <td>176.300003</td>\n",
              "      <td>175.402451</td>\n",
              "      <td>90370200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>48.806187</td>\n",
              "      <td>-1.033479</td>\n",
              "      <td>-0.723696</td>\n",
              "      <td>-0.309782</td>\n",
              "      <td>-3.870193</td>\n",
              "      <td>44.185681</td>\n",
              "      <td>1</td>\n",
              "      <td>0.166936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>902</th>\n",
              "      <td>2023-09-13</td>\n",
              "      <td>174.210007</td>\n",
              "      <td>173.323090</td>\n",
              "      <td>84267900</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>40.699856</td>\n",
              "      <td>-1.490935</td>\n",
              "      <td>-0.877144</td>\n",
              "      <td>-0.613791</td>\n",
              "      <td>-9.859543</td>\n",
              "      <td>39.386913</td>\n",
              "      <td>1</td>\n",
              "      <td>0.151901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>903</th>\n",
              "      <td>2023-09-14</td>\n",
              "      <td>175.740005</td>\n",
              "      <td>174.845306</td>\n",
              "      <td>60895800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>49.057149</td>\n",
              "      <td>-1.710921</td>\n",
              "      <td>-1.043900</td>\n",
              "      <td>-0.667021</td>\n",
              "      <td>-11.849350</td>\n",
              "      <td>41.689687</td>\n",
              "      <td>0</td>\n",
              "      <td>0.186515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>904</th>\n",
              "      <td>2023-09-15</td>\n",
              "      <td>175.009995</td>\n",
              "      <td>174.119003</td>\n",
              "      <td>109205100</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>44.451268</td>\n",
              "      <td>-1.921715</td>\n",
              "      <td>-1.219463</td>\n",
              "      <td>-0.702252</td>\n",
              "      <td>-12.794525</td>\n",
              "      <td>44.533334</td>\n",
              "      <td>0</td>\n",
              "      <td>0.180323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905</th>\n",
              "      <td>2023-09-18</td>\n",
              "      <td>177.970001</td>\n",
              "      <td>177.063950</td>\n",
              "      <td>67257600</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>46.717932</td>\n",
              "      <td>-1.830042</td>\n",
              "      <td>-1.341578</td>\n",
              "      <td>-0.488464</td>\n",
              "      <td>-11.431519</td>\n",
              "      <td>46.930296</td>\n",
              "      <td>0</td>\n",
              "      <td>0.237152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>906</th>\n",
              "      <td>2023-09-19</td>\n",
              "      <td>179.070007</td>\n",
              "      <td>178.158340</td>\n",
              "      <td>51826900</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>41.852228</td>\n",
              "      <td>-1.650062</td>\n",
              "      <td>-1.403275</td>\n",
              "      <td>-0.246787</td>\n",
              "      <td>-10.575897</td>\n",
              "      <td>49.874047</td>\n",
              "      <td>0</td>\n",
              "      <td>0.271960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>907</th>\n",
              "      <td>2023-09-20</td>\n",
              "      <td>175.490005</td>\n",
              "      <td>174.596573</td>\n",
              "      <td>58436200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>30.412434</td>\n",
              "      <td>-1.774378</td>\n",
              "      <td>-1.477496</td>\n",
              "      <td>-0.296882</td>\n",
              "      <td>-7.382233</td>\n",
              "      <td>41.832803</td>\n",
              "      <td>0</td>\n",
              "      <td>0.350081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>908</th>\n",
              "      <td>2023-09-21</td>\n",
              "      <td>173.929993</td>\n",
              "      <td>173.044495</td>\n",
              "      <td>63047900</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>28.474432</td>\n",
              "      <td>-1.975368</td>\n",
              "      <td>-1.577070</td>\n",
              "      <td>-0.398297</td>\n",
              "      <td>-3.611526</td>\n",
              "      <td>40.639619</td>\n",
              "      <td>0</td>\n",
              "      <td>0.355005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>909</th>\n",
              "      <td>2023-09-22</td>\n",
              "      <td>174.789993</td>\n",
              "      <td>173.900116</td>\n",
              "      <td>56725400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>26.824635</td>\n",
              "      <td>-2.042072</td>\n",
              "      <td>-1.670071</td>\n",
              "      <td>-0.372002</td>\n",
              "      <td>-3.372742</td>\n",
              "      <td>41.619514</td>\n",
              "      <td>0</td>\n",
              "      <td>0.382324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>910</th>\n",
              "      <td>2023-09-25</td>\n",
              "      <td>176.080002</td>\n",
              "      <td>175.183578</td>\n",
              "      <td>46172700</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>29.174382</td>\n",
              "      <td>-1.968678</td>\n",
              "      <td>-1.729792</td>\n",
              "      <td>-0.238886</td>\n",
              "      <td>-3.263290</td>\n",
              "      <td>40.729973</td>\n",
              "      <td>0</td>\n",
              "      <td>0.403720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>911</th>\n",
              "      <td>2023-09-26</td>\n",
              "      <td>171.960007</td>\n",
              "      <td>171.084564</td>\n",
              "      <td>64588900</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>31.768310</td>\n",
              "      <td>-2.215727</td>\n",
              "      <td>-1.826979</td>\n",
              "      <td>-0.388748</td>\n",
              "      <td>-4.317886</td>\n",
              "      <td>36.947296</td>\n",
              "      <td>1</td>\n",
              "      <td>0.166343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>912</th>\n",
              "      <td>2023-09-27</td>\n",
              "      <td>170.429993</td>\n",
              "      <td>169.562332</td>\n",
              "      <td>66921800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>36.398394</td>\n",
              "      <td>-2.505465</td>\n",
              "      <td>-1.962676</td>\n",
              "      <td>-0.542789</td>\n",
              "      <td>-3.760757</td>\n",
              "      <td>33.188255</td>\n",
              "      <td>1</td>\n",
              "      <td>0.176770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>913</th>\n",
              "      <td>2023-09-28</td>\n",
              "      <td>170.690002</td>\n",
              "      <td>169.821014</td>\n",
              "      <td>56294400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>35.512682</td>\n",
              "      <td>-2.683280</td>\n",
              "      <td>-2.106797</td>\n",
              "      <td>-0.576483</td>\n",
              "      <td>-5.024292</td>\n",
              "      <td>35.576254</td>\n",
              "      <td>1</td>\n",
              "      <td>0.148790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>914</th>\n",
              "      <td>2023-09-29</td>\n",
              "      <td>171.210007</td>\n",
              "      <td>170.338348</td>\n",
              "      <td>51814200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>33.822967</td>\n",
              "      <td>-2.750746</td>\n",
              "      <td>-2.235587</td>\n",
              "      <td>-0.515159</td>\n",
              "      <td>-3.780655</td>\n",
              "      <td>37.756910</td>\n",
              "      <td>1</td>\n",
              "      <td>0.197260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>915</th>\n",
              "      <td>2023-10-02</td>\n",
              "      <td>173.750000</td>\n",
              "      <td>172.865433</td>\n",
              "      <td>52164500</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>44.831799</td>\n",
              "      <td>-2.570666</td>\n",
              "      <td>-2.302602</td>\n",
              "      <td>-0.268063</td>\n",
              "      <td>-4.198517</td>\n",
              "      <td>44.671298</td>\n",
              "      <td>1</td>\n",
              "      <td>0.251361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>916</th>\n",
              "      <td>2023-10-03</td>\n",
              "      <td>172.399994</td>\n",
              "      <td>171.522293</td>\n",
              "      <td>49594600</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>46.218129</td>\n",
              "      <td>-2.507427</td>\n",
              "      <td>-2.343567</td>\n",
              "      <td>-0.163860</td>\n",
              "      <td>-6.636047</td>\n",
              "      <td>47.271229</td>\n",
              "      <td>1</td>\n",
              "      <td>0.365447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>917</th>\n",
              "      <td>2023-10-04</td>\n",
              "      <td>173.660004</td>\n",
              "      <td>172.775879</td>\n",
              "      <td>53020300</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>45.604378</td>\n",
              "      <td>-2.329305</td>\n",
              "      <td>-2.340715</td>\n",
              "      <td>0.011410</td>\n",
              "      <td>-1.820694</td>\n",
              "      <td>49.105305</td>\n",
              "      <td>1</td>\n",
              "      <td>0.369749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>918</th>\n",
              "      <td>2023-10-05</td>\n",
              "      <td>174.910004</td>\n",
              "      <td>174.019516</td>\n",
              "      <td>48527900</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>49.793226</td>\n",
              "      <td>-2.063999</td>\n",
              "      <td>-2.285372</td>\n",
              "      <td>0.221373</td>\n",
              "      <td>0.975021</td>\n",
              "      <td>56.409554</td>\n",
              "      <td>1</td>\n",
              "      <td>0.414656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>919</th>\n",
              "      <td>2023-10-06</td>\n",
              "      <td>177.490005</td>\n",
              "      <td>176.586411</td>\n",
              "      <td>57224100</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>48.991637</td>\n",
              "      <td>-1.627849</td>\n",
              "      <td>-2.153867</td>\n",
              "      <td>0.526018</td>\n",
              "      <td>2.686295</td>\n",
              "      <td>62.963703</td>\n",
              "      <td>1</td>\n",
              "      <td>0.415359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>920</th>\n",
              "      <td>2023-10-09</td>\n",
              "      <td>178.990005</td>\n",
              "      <td>178.078766</td>\n",
              "      <td>42390800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>49.834749</td>\n",
              "      <td>-1.148538</td>\n",
              "      <td>-1.952801</td>\n",
              "      <td>0.804263</td>\n",
              "      <td>2.895187</td>\n",
              "      <td>65.802095</td>\n",
              "      <td>0</td>\n",
              "      <td>0.394591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>921</th>\n",
              "      <td>2023-10-10</td>\n",
              "      <td>178.389999</td>\n",
              "      <td>177.481812</td>\n",
              "      <td>43698000</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>56.833148</td>\n",
              "      <td>-0.807541</td>\n",
              "      <td>-1.723749</td>\n",
              "      <td>0.916209</td>\n",
              "      <td>6.397247</td>\n",
              "      <td>67.324726</td>\n",
              "      <td>0</td>\n",
              "      <td>0.537055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>922</th>\n",
              "      <td>2023-10-11</td>\n",
              "      <td>179.800003</td>\n",
              "      <td>178.884644</td>\n",
              "      <td>47551100</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>63.929772</td>\n",
              "      <td>-0.419268</td>\n",
              "      <td>-1.462853</td>\n",
              "      <td>1.043585</td>\n",
              "      <td>9.322311</td>\n",
              "      <td>69.619239</td>\n",
              "      <td>0</td>\n",
              "      <td>0.452408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>923</th>\n",
              "      <td>2023-10-12</td>\n",
              "      <td>180.710007</td>\n",
              "      <td>179.790009</td>\n",
              "      <td>56743100</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>64.015163</td>\n",
              "      <td>-0.038065</td>\n",
              "      <td>-1.177895</td>\n",
              "      <td>1.139831</td>\n",
              "      <td>9.968994</td>\n",
              "      <td>69.448352</td>\n",
              "      <td>0</td>\n",
              "      <td>0.379180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>924</th>\n",
              "      <td>2023-10-13</td>\n",
              "      <td>178.850006</td>\n",
              "      <td>177.939484</td>\n",
              "      <td>51427100</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>56.385430</td>\n",
              "      <td>0.113412</td>\n",
              "      <td>-0.919634</td>\n",
              "      <td>1.033046</td>\n",
              "      <td>7.601135</td>\n",
              "      <td>61.777453</td>\n",
              "      <td>0</td>\n",
              "      <td>0.334453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>925</th>\n",
              "      <td>2023-10-16</td>\n",
              "      <td>178.720001</td>\n",
              "      <td>177.810104</td>\n",
              "      <td>52517000</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>69.095798</td>\n",
              "      <td>0.220478</td>\n",
              "      <td>-0.691611</td>\n",
              "      <td>0.912089</td>\n",
              "      <td>4.944672</td>\n",
              "      <td>64.467109</td>\n",
              "      <td>0</td>\n",
              "      <td>0.302987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>2023-10-17</td>\n",
              "      <td>177.149994</td>\n",
              "      <td>176.248108</td>\n",
              "      <td>57549400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>68.940127</td>\n",
              "      <td>0.177244</td>\n",
              "      <td>-0.517840</td>\n",
              "      <td>0.695085</td>\n",
              "      <td>4.725815</td>\n",
              "      <td>61.556032</td>\n",
              "      <td>0</td>\n",
              "      <td>0.142711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>2023-10-18</td>\n",
              "      <td>175.839996</td>\n",
              "      <td>174.944794</td>\n",
              "      <td>54764400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>63.704051</td>\n",
              "      <td>0.037384</td>\n",
              "      <td>-0.406795</td>\n",
              "      <td>0.444180</td>\n",
              "      <td>2.168915</td>\n",
              "      <td>55.260700</td>\n",
              "      <td>0</td>\n",
              "      <td>0.147775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>2023-10-19</td>\n",
              "      <td>175.460007</td>\n",
              "      <td>174.566742</td>\n",
              "      <td>59302900</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>61.394146</td>\n",
              "      <td>-0.102777</td>\n",
              "      <td>-0.345992</td>\n",
              "      <td>0.243215</td>\n",
              "      <td>0.547226</td>\n",
              "      <td>52.953821</td>\n",
              "      <td>0</td>\n",
              "      <td>0.178858</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7edca83-06b6-4600-b488-f7b7b35ed602')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d7edca83-06b6-4600-b488-f7b7b35ed602 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d7edca83-06b6-4600-b488-f7b7b35ed602');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7c12cef7-2002-4f38-9b43-b431d53c525b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c12cef7-2002-4f38-9b43-b431d53c525b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7c12cef7-2002-4f38-9b43-b431d53c525b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          Date       Close   Adj Close     Volume Ticker        RSI      MACD  \\\n",
              "879 2023-08-10  177.970001  176.825150   54686900   AAPL  24.553693 -2.230426   \n",
              "880 2023-08-11  177.789993  176.884857   51988100   AAPL  22.434627 -2.638519   \n",
              "881 2023-08-14  179.460007  178.546371   43675600   AAPL  24.697356 -2.795640   \n",
              "882 2023-08-15  177.449997  176.546585   43622600   AAPL  20.647179 -3.046407   \n",
              "883 2023-08-16  176.570007  175.671066   46964900   AAPL  20.938797 -3.278003   \n",
              "884 2023-08-17  174.000000  173.114151   66062900   AAPL  11.710541 -3.626066   \n",
              "885 2023-08-18  174.490005  173.601669   61114200   AAPL  11.303821 -3.818553   \n",
              "886 2023-08-21  175.839996  174.944794   46311900   AAPL  15.830985 -3.818701   \n",
              "887 2023-08-22  177.229996  176.327698   42084200   AAPL  21.959189 -3.664983   \n",
              "888 2023-08-23  181.119995  180.197922   52722800   AAPL  33.340796 -3.194046   \n",
              "889 2023-08-24  176.380005  175.482056   54945800   AAPL  39.254553 -3.164873   \n",
              "890 2023-08-25  178.610001  177.700699   51449600   AAPL  50.002455 -2.928964   \n",
              "891 2023-08-28  180.190002  179.272644   43820700   AAPL  51.280930 -2.585359   \n",
              "892 2023-08-29  184.119995  183.182632   53003900   AAPL  61.422280 -1.974783   \n",
              "893 2023-08-30  187.649994  186.694656   60813900   AAPL  66.358834 -1.193745   \n",
              "894 2023-08-31  187.869995  186.913528   60794500   AAPL  66.535404 -0.550756   \n",
              "895 2023-09-01  189.460007  188.495468   45732600   AAPL  66.447360  0.085480   \n",
              "896 2023-09-05  189.699997  188.734238   45280000   AAPL  71.393667  0.602029   \n",
              "897 2023-09-06  182.910004  181.978806   81755800   AAPL  59.177786  0.460978   \n",
              "898 2023-09-07  177.559998  176.656021  112488800   AAPL  54.769549 -0.079396   \n",
              "899 2023-09-08  178.179993  177.272858   65551300   AAPL  54.926533 -0.452655   \n",
              "900 2023-09-11  179.360001  178.446869   58953100   AAPL  54.721020 -0.646282   \n",
              "901 2023-09-12  176.300003  175.402451   90370200   AAPL  48.806187 -1.033479   \n",
              "902 2023-09-13  174.210007  173.323090   84267900   AAPL  40.699856 -1.490935   \n",
              "903 2023-09-14  175.740005  174.845306   60895800   AAPL  49.057149 -1.710921   \n",
              "904 2023-09-15  175.009995  174.119003  109205100   AAPL  44.451268 -1.921715   \n",
              "905 2023-09-18  177.970001  177.063950   67257600   AAPL  46.717932 -1.830042   \n",
              "906 2023-09-19  179.070007  178.158340   51826900   AAPL  41.852228 -1.650062   \n",
              "907 2023-09-20  175.490005  174.596573   58436200   AAPL  30.412434 -1.774378   \n",
              "908 2023-09-21  173.929993  173.044495   63047900   AAPL  28.474432 -1.975368   \n",
              "909 2023-09-22  174.789993  173.900116   56725400   AAPL  26.824635 -2.042072   \n",
              "910 2023-09-25  176.080002  175.183578   46172700   AAPL  29.174382 -1.968678   \n",
              "911 2023-09-26  171.960007  171.084564   64588900   AAPL  31.768310 -2.215727   \n",
              "912 2023-09-27  170.429993  169.562332   66921800   AAPL  36.398394 -2.505465   \n",
              "913 2023-09-28  170.690002  169.821014   56294400   AAPL  35.512682 -2.683280   \n",
              "914 2023-09-29  171.210007  170.338348   51814200   AAPL  33.822967 -2.750746   \n",
              "915 2023-10-02  173.750000  172.865433   52164500   AAPL  44.831799 -2.570666   \n",
              "916 2023-10-03  172.399994  171.522293   49594600   AAPL  46.218129 -2.507427   \n",
              "917 2023-10-04  173.660004  172.775879   53020300   AAPL  45.604378 -2.329305   \n",
              "918 2023-10-05  174.910004  174.019516   48527900   AAPL  49.793226 -2.063999   \n",
              "919 2023-10-06  177.490005  176.586411   57224100   AAPL  48.991637 -1.627849   \n",
              "920 2023-10-09  178.990005  178.078766   42390800   AAPL  49.834749 -1.148538   \n",
              "921 2023-10-10  178.389999  177.481812   43698000   AAPL  56.833148 -0.807541   \n",
              "922 2023-10-11  179.800003  178.884644   47551100   AAPL  63.929772 -0.419268   \n",
              "923 2023-10-12  180.710007  179.790009   56743100   AAPL  64.015163 -0.038065   \n",
              "924 2023-10-13  178.850006  177.939484   51427100   AAPL  56.385430  0.113412   \n",
              "925 2023-10-16  178.720001  177.810104   52517000   AAPL  69.095798  0.220478   \n",
              "926 2023-10-17  177.149994  176.248108   57549400   AAPL  68.940127  0.177244   \n",
              "927 2023-10-18  175.839996  174.944794   54764400   AAPL  63.704051  0.037384   \n",
              "928 2023-10-19  175.460007  174.566742   59302900   AAPL  61.394146 -0.102777   \n",
              "\n",
              "     MACD_Signal  MACD_Hist   Momentum  Ultimate Oscillator  buy  prediction  \n",
              "879     0.032167  -2.262594 -15.151932            26.081248    0    0.313292  \n",
              "880    -0.501970  -2.136549 -17.685425            28.332647    0    0.251857  \n",
              "881    -0.960704  -1.834936 -16.639908            32.224822    0    0.163717  \n",
              "882    -1.377845  -1.668563 -17.805099            37.441234    0    0.180028  \n",
              "883    -1.757876  -1.520127 -15.670120            37.793791    1    0.187729  \n",
              "884    -2.131514  -1.494552 -16.826096            29.768756    1    0.202567  \n",
              "885    -2.468922  -1.349631  -7.217651            35.097160    1    0.193149  \n",
              "886    -2.738878  -1.079823  -2.754730            42.351156    1    0.384552  \n",
              "887    -2.924099  -0.740884  -2.315704            44.018561    1    0.366074  \n",
              "888    -2.978088  -0.215957   3.154144            47.949240    1    0.365870  \n",
              "889    -3.015445  -0.149428  -1.343094            44.944673    1    0.378145  \n",
              "890    -2.998149   0.069185   0.815842            51.652539    1    0.372489  \n",
              "891    -2.915591   0.330232   0.726273            57.331010    1    0.564376  \n",
              "892    -2.727429   0.752647   6.636047            61.021675    0    0.540565  \n",
              "893    -2.420692   1.226948  11.023590            64.419697    0    0.554845  \n",
              "894    -2.046705   1.495949  13.799377            62.147184    0    0.488132  \n",
              "895    -1.620268   1.705748  14.893799            60.107666    0    0.455290  \n",
              "896    -1.175809   1.777838  13.789444            71.041564    0    0.266339  \n",
              "897    -0.848451   1.309429   5.651108            57.500625    0    0.243822  \n",
              "898    -0.694640   0.615244  -3.541901            53.989427    0    0.215394  \n",
              "899    -0.646243   0.193589   1.790802            48.146750    0    0.215388  \n",
              "900    -0.646251  -0.000031   0.746170            45.820708    0    0.209773  \n",
              "901    -0.723696  -0.309782  -3.870193            44.185681    1    0.166936  \n",
              "902    -0.877144  -0.613791  -9.859543            39.386913    1    0.151901  \n",
              "903    -1.043900  -0.667021 -11.849350            41.689687    0    0.186515  \n",
              "904    -1.219463  -0.702252 -12.794525            44.533334    0    0.180323  \n",
              "905    -1.341578  -0.488464 -11.431519            46.930296    0    0.237152  \n",
              "906    -1.403275  -0.246787 -10.575897            49.874047    0    0.271960  \n",
              "907    -1.477496  -0.296882  -7.382233            41.832803    0    0.350081  \n",
              "908    -1.577070  -0.398297  -3.611526            40.639619    0    0.355005  \n",
              "909    -1.670071  -0.372002  -3.372742            41.619514    0    0.382324  \n",
              "910    -1.729792  -0.238886  -3.263290            40.729973    0    0.403720  \n",
              "911    -1.826979  -0.388748  -4.317886            36.947296    1    0.166343  \n",
              "912    -1.962676  -0.542789  -3.760757            33.188255    1    0.176770  \n",
              "913    -2.106797  -0.576483  -5.024292            35.576254    1    0.148790  \n",
              "914    -2.235587  -0.515159  -3.780655            37.756910    1    0.197260  \n",
              "915    -2.302602  -0.268063  -4.198517            44.671298    1    0.251361  \n",
              "916    -2.343567  -0.163860  -6.636047            47.271229    1    0.365447  \n",
              "917    -2.340715   0.011410  -1.820694            49.105305    1    0.369749  \n",
              "918    -2.285372   0.221373   0.975021            56.409554    1    0.414656  \n",
              "919    -2.153867   0.526018   2.686295            62.963703    1    0.415359  \n",
              "920    -1.952801   0.804263   2.895187            65.802095    0    0.394591  \n",
              "921    -1.723749   0.916209   6.397247            67.324726    0    0.537055  \n",
              "922    -1.462853   1.043585   9.322311            69.619239    0    0.452408  \n",
              "923    -1.177895   1.139831   9.968994            69.448352    0    0.379180  \n",
              "924    -0.919634   1.033046   7.601135            61.777453    0    0.334453  \n",
              "925    -0.691611   0.912089   4.944672            64.467109    0    0.302987  \n",
              "926    -0.517840   0.695085   4.725815            61.556032    0    0.142711  \n",
              "927    -0.406795   0.444180   2.168915            55.260700    0    0.147775  \n",
              "928    -0.345992   0.243215   0.547226            52.953821    0    0.178858  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_aapl_filtered.tail(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "rr9W7DcdFrf5"
      },
      "outputs": [],
      "source": [
        "df_aapl_filtered.to_csv('AAPL_predictions.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcYWfHZiGat7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
